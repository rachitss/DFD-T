{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd6ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\W\\VS\\VS Folder\\DFD\\env1\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import resnet18\n",
    "from albumentations import Normalize, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing as mp\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Running on device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437a514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\rachi\\AppData\\Local\\Temp\\ipykernel_28608\\1463474768.py:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  train_dir = 'D:\\W\\VS\\VS Folder\\DFD\\DFDC MTCNN Extracted/'\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'D:\\W\\VS\\VS Folder\\DFD\\DFDC MTCNN Extracted/'\n",
    "SAVE_PATH = 'googleViT.pth' # The location where the model should be saved.\n",
    "PRETRAINED_MODEL_PATH = ''\n",
    "N_FACES = 5\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = mp.cpu_count()\n",
    "\n",
    "WARM_UP_EPOCHS = 10\n",
    "WARM_UP_LR = 1e-4\n",
    "FINE_TUNE_EPOCHS = 100\n",
    "FINE_TUNE_LR = 1e-6\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "EPSILON = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea9da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(preds, labels):\n",
    "    '''\n",
    "    Parameters:\n",
    "        preds: The predictions.\n",
    "        labels: The labels.\n",
    "\n",
    "    Returns:\n",
    "        f1 score\n",
    "    '''\n",
    "\n",
    "    labels = np.array(labels, dtype=np.uint8)\n",
    "    preds = (np.array(preds) >= THRESHOLD).astype(np.uint8)\n",
    "    tp = np.count_nonzero(np.logical_and(labels, preds))\n",
    "    tn = np.count_nonzero(np.logical_not(np.logical_or(labels, preds)))\n",
    "    fp = np.count_nonzero(np.logical_not(labels)) - tn\n",
    "    fn = np.count_nonzero(labels) - tp\n",
    "    precision = tp / (tp + fp + EPSILON)\n",
    "    recall = tp / (tp + fn + EPSILON)\n",
    "    f1 = (2 * precision * recall) / (precision + recall + EPSILON)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "def train_the_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    best_val_loss=1e7,\n",
    "    best_val_logloss=1e7,\n",
    "    save_the_best_on='val_logloss'\n",
    "):\n",
    "    '''\n",
    "    Parameters:\n",
    "        model: The model needs to be trained.\n",
    "        criterion: Loss function.\n",
    "        optimizer: The optimizer.\n",
    "        epochs: The number of epochs\n",
    "        train_dataloader: The dataloader used to generate training samples.\n",
    "        val_dataloader: The dataloader used to generate validation samples.\n",
    "        best_val_loss: The initial value of the best val loss (default: 1e7.)\n",
    "        best_val_logloss: The initial value of the best val log loss (default: 1e7.)\n",
    "        save_the_best_on: Whether to save the best model based on \"val_loss\" or \"val_logloss\" (default: val_logloss.)\n",
    "\n",
    "    Returns:\n",
    "        losses: All computed losses.\n",
    "        val_losses: All computed val_losses.\n",
    "        loglosses: All computed loglosses.\n",
    "        val_loglosses: All computed val_loglosses.\n",
    "        f1_scores: All computed f1_scores.\n",
    "        val_f1_scores: All computed val_f1_scores.\n",
    "        best_val_loss: New value of the best val loss.\n",
    "        best_val_logloss: New value of the best val log loss.\n",
    "        best_model_state_dict: The state_dict of the best model.\n",
    "        best_optimizer_state_dict: The state_dict of the optimizer corresponds to the best model.\n",
    "    '''\n",
    "\n",
    "    losses = np.zeros(epochs)\n",
    "    val_losses = np.zeros(epochs)\n",
    "    loglosses = np.zeros(epochs)\n",
    "    val_loglosses = np.zeros(epochs)\n",
    "    f1_scores = np.zeros(epochs)\n",
    "    val_f1_scores = np.zeros(epochs)\n",
    "    best_model_state_dict = None\n",
    "    best_optimizer_state_dict = None\n",
    "\n",
    "    logloss = nn.BCELoss()\n",
    "\n",
    "    for i in tqdm(range(epochs)):\n",
    "        batch_losses = []\n",
    "        train_pbar = tqdm(train_dataloader)\n",
    "        train_pbar.desc = f'Epoch {i+1}'\n",
    "        classifier.train()\n",
    "\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for i_batch, sample_batched in enumerate(train_pbar):\n",
    "            # Make prediction.\n",
    "            faces = sample_batched['faces'].to(device)\n",
    "            labels = sample_batched['label'].to(device)\n",
    "            y_pred = classifier(faces)\n",
    "\n",
    "            all_labels.extend(labels.squeeze(dim=-1).tolist())\n",
    "            all_preds.extend(y_pred.squeeze(dim=-1).tolist())\n",
    "\n",
    "            # Compute loss.\n",
    "            loss = criterion(y_pred, labels)\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Display some information in progress-bar.\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': batch_losses[-1]\n",
    "            })\n",
    "\n",
    "        # Compute scores.\n",
    "        loglosses[i] = logloss(torch.tensor(all_preds).to(device), torch.tensor(all_labels).to(device))\n",
    "        f1_scores[i] = calculate_f1(all_preds, all_labels)\n",
    "\n",
    "        # Compute batch loss (average).\n",
    "        losses[i] = np.array(batch_losses).mean()\n",
    "\n",
    "\n",
    "        # Compute val loss\n",
    "        val_batch_losses = []\n",
    "        val_pbar = tqdm(val_dataloader)\n",
    "        val_pbar.desc = 'Validating'\n",
    "        classifier.eval()\n",
    "\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for i_batch, sample_batched in enumerate(val_pbar):\n",
    "            # Make prediction.\n",
    "            faces = sample_batched['faces'].to(device)\n",
    "            labels = sample_batched['label'].to(device)\n",
    "            y_pred = classifier(faces)\n",
    "\n",
    "            all_labels.extend(labels.squeeze(dim=-1).tolist())\n",
    "            all_preds.extend(y_pred.squeeze(dim=-1).tolist())\n",
    "\n",
    "            # Compute val loss.\n",
    "            val_loss = criterion(y_pred, labels)\n",
    "            val_batch_losses.append(val_loss.item())\n",
    "\n",
    "            # Display some information in progress-bar.\n",
    "            val_pbar.set_postfix({\n",
    "                'val_loss': val_batch_losses[-1]\n",
    "            })\n",
    "\n",
    "        # Compute val scores.\n",
    "        val_loglosses[i] = logloss(torch.tensor(all_preds).to(device), torch.tensor(all_labels).to(device))\n",
    "        val_f1_scores[i] = calculate_f1(all_preds, all_labels)\n",
    "\n",
    "        val_losses[i] = np.array(val_batch_losses).mean()\n",
    "        print(f'loss: {losses[i]} | val loss: {val_losses[i]} | f1: {f1_scores[i]} | val f1: {val_f1_scores[i]} | log loss: {loglosses[i]} | val log loss: {val_loglosses[i]}')\n",
    "        \n",
    "        # Update the best values\n",
    "        if val_losses[i] < best_val_loss:\n",
    "            best_val_loss = val_losses[i]\n",
    "            if save_the_best_on == 'val_loss':\n",
    "                print('Found a better checkpoint!')\n",
    "                best_model_state_dict = classifier.state_dict()\n",
    "                best_optimizer_state_dict = optimizer.state_dict()\n",
    "        if val_loglosses[i] < best_val_logloss:\n",
    "            best_val_logloss = val_loglosses[i]\n",
    "            if save_the_best_on == 'val_logloss':\n",
    "                print('Found a better checkpoint!')\n",
    "                best_model_state_dict = classifier.state_dict()\n",
    "                best_optimizer_state_dict = optimizer.state_dict()\n",
    "            \n",
    "    return losses, val_losses, loglosses, val_loglosses, f1_scores, val_f1_scores, best_val_loss, best_val_logloss, best_model_state_dict, best_optimizer_state_dict\n",
    "\n",
    "\n",
    "def visualize_results(\n",
    "    losses,\n",
    "    val_losses,\n",
    "    loglosses,\n",
    "    val_loglosses,\n",
    "    f1_scores,\n",
    "    val_f1_scores\n",
    "):\n",
    "    '''\n",
    "    Parameters:\n",
    "        losses: A list of losses.\n",
    "        val_losses: A list of val losses.\n",
    "        loglosses: A list of loglosses.\n",
    "        val_loglosses: A list of val loglosses.\n",
    "        f1_scores: A list of f1 scores.\n",
    "        val_f1_scores: A list of val f1 scores.\n",
    "    '''\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    ax.plot(np.arange(1, len(losses) + 1), losses)\n",
    "    ax.plot(np.arange(1, len(val_losses) + 1), val_losses)\n",
    "    ax.set_xlabel('epoch', fontsize='xx-large')\n",
    "    ax.set_ylabel('focal loss', fontsize='xx-large')\n",
    "    ax.legend(\n",
    "        ['loss', 'val loss'],\n",
    "        loc='upper right',\n",
    "        fontsize='xx-large',\n",
    "        shadow=True\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    ax.plot(np.arange(1, len(loglosses) + 1), loglosses)\n",
    "    ax.plot(np.arange(1, len(val_loglosses) + 1), val_loglosses)\n",
    "    ax.set_xlabel('epoch', fontsize='xx-large')\n",
    "    ax.set_ylabel('log loss', fontsize='xx-large')\n",
    "    ax.legend(\n",
    "        ['log loss', 'val log loss'],\n",
    "        loc='upper right',\n",
    "        fontsize='xx-large',\n",
    "        shadow=True\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    ax.plot(np.arange(1, len(f1_scores) + 1), f1_scores)\n",
    "    ax.plot(np.arange(1, len(val_f1_scores) + 1), val_f1_scores)\n",
    "    ax.set_xlabel('epoch', fontsize='xx-large')\n",
    "    ax.set_ylabel('f1 score', fontsize='xx-large')\n",
    "    ax.legend(\n",
    "        ['f1', 'val f1'],\n",
    "        loc='upper left',\n",
    "        fontsize='xx-large',\n",
    "        shadow=True\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9efe46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepfakeClassifier(nn.Module):\n",
    "    def __init__(self, encoder, in_channels=3, num_classes=1):\n",
    "        super(DeepfakeClassifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        # Modify input layer.\n",
    "        self.encoder.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        # Modify output layer.\n",
    "        self.encoder.fc = nn.Linear(512 * 1, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.encoder(x))\n",
    "    \n",
    "    def freeze_all_layers(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def freeze_middle_layers(self):\n",
    "        self.freeze_all_layers()\n",
    "        \n",
    "        for param in self.encoder.conv1.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.encoder.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfreeze_all_layers(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, img_dirs, labels, n_faces=1, preprocess=None):\n",
    "        self.img_dirs = img_dirs\n",
    "        self.labels = labels\n",
    "        self.n_faces = n_faces\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_dirs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_dir = self.img_dirs[idx]\n",
    "        label = self.labels[idx]\n",
    "        face_paths = glob.glob(f'{img_dir}/*.png')\n",
    "\n",
    "        if len(face_paths) >= self.n_faces:\n",
    "            sample = np.random.choice(face_paths, self.n_faces, replace=False)\n",
    "        else:\n",
    "            sample = np.random.choice(face_paths, self.n_faces, replace=True)\n",
    "            \n",
    "        faces = []\n",
    "        \n",
    "        for face_path in sample:\n",
    "            face = cv2.imread(face_path, 1)\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            if self.preprocess is not None:\n",
    "                augmented = self.preprocess(image=face)\n",
    "                face = augmented['image']\n",
    "            faces.append(face)\n",
    "\n",
    "        return {'faces': np.concatenate(faces, axis=-1).transpose(2, 0, 1), 'label': np.array([label], dtype=float)}\n",
    "    \n",
    "    \n",
    "class FaceValDataset(Dataset):\n",
    "    def __init__(self, img_dirs, labels, n_faces=1, preprocess=None):\n",
    "        self.img_dirs = img_dirs\n",
    "        self.labels = labels\n",
    "        self.n_faces = n_faces\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_dirs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_dir = self.img_dirs[idx]\n",
    "        label = self.labels[idx]\n",
    "        face_paths = glob.glob(f'{img_dir}/*.png')\n",
    "\n",
    "        face_indices = [\n",
    "            path.split('\\\\')[-1].split('.')[0].split('_')[0]\n",
    "            for path in face_paths\n",
    "        ]        \n",
    "        max_idx = np.max(np.array(face_indices, dtype=np.uint32))\n",
    "\n",
    "        selected_paths = []\n",
    "\n",
    "        for i in range(self.n_faces):\n",
    "            stride = int((max_idx + 1)/(self.n_faces**2))\n",
    "            sample = np.linspace(i*stride, max_idx + i*stride, self.n_faces).astype(int)\n",
    "\n",
    "            # Get faces\n",
    "            for idx in sample:\n",
    "                paths = glob.glob(f'{img_dir}/{idx}*.png')\n",
    "\n",
    "                selected_paths.extend(paths)\n",
    "\n",
    "                if len(selected_paths) >= self.n_faces:\n",
    "                    break\n",
    "            \n",
    "            if len(selected_paths) >= self.n_faces:\n",
    "                break\n",
    "\n",
    "        faces = []\n",
    "\n",
    "        selected_paths = selected_paths[:self.n_faces] # Get top\n",
    "        for selected_path in selected_paths:\n",
    "            img = cv2.imread(selected_path, 1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            faces.append(img)\n",
    "\n",
    "        if self.preprocess is not None:\n",
    "            for j in range(len(faces)):\n",
    "                augmented = self.preprocess(image=faces[j])\n",
    "                faces[j] = augmented['image']\n",
    "\n",
    "        faces = np.concatenate(faces, axis=-1).transpose(2, 0, 1)\n",
    "\n",
    "        return {\n",
    "            'faces': faces,\n",
    "            'label': np.array([label], dtype=float)\n",
    "        }\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, sample_weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.sample_weight = sample_weight\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        target = target.float()\n",
    "        max_val = (-logit).clamp(min=0)\n",
    "        loss = logit - logit * target + max_val + \\\n",
    "               ((-max_val).exp() + (-logit - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-logit * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        if len(loss.size())==2:\n",
    "            loss = loss.sum(dim=1)\n",
    "        if self.sample_weight is not None:\n",
    "            loss = loss * self.sample_weight\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c829b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(train_dir, 'metadata.csv'))\n",
    "train_df['path'] = train_df['filename'].apply(lambda x: os.path.join(train_dir, x.split('.')[0]))\n",
    "train_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
